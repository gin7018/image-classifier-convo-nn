{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNuOGtZIyL/6sr5BUE1gDlE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gin7018/image-classifier-convo-nn/blob/main/image_classifier_convolutional_nn_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "nWkNKK-VbTB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import transformers\n",
        "from transformers.modeling_utils import PreTrainedModel\n",
        "\n",
        "class ImageClassifierModel(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, num_labels=10):\n",
        "    super(ImageClassifierModel, self).__init__()\n",
        "\n",
        "    self.convo1= torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
        "    self.convo2= torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "    self.max_pooling1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.convo3= torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "    self.convo4= torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "    self.max_pooling2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.connected_layer1 = torch.nn.Linear(in_features=1600, out_features=128)\n",
        "    self.activation_fun = torch.nn.ReLU()\n",
        "    self.connected_layer2 = torch.nn.Linear(in_features=128, out_features=num_labels)\n",
        "\n",
        "  def forward(self, image_input):\n",
        "    output = self.convo1(image_input)\n",
        "    output= self.convo2(output)\n",
        "    output = self.max_pooling1(output)\n",
        "\n",
        "    output = self.convo3(output)\n",
        "    output = self.convo4(output)\n",
        "    output = self.max_pooling2(output)\n",
        "\n",
        "    output = output.reshape(output.size(0), -1)\n",
        "\n",
        "    output = self.connected_layer1(output)\n",
        "    output = self.activation_fun(output)\n",
        "    output = self.connected_layer2(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "f1yRSJ15khzb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbKIlT_vZwAs",
        "outputId": "d5d58074-6ce2-427c-e219-c58774be77a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 28753153.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "data_transformer = transforms.Compose([transforms.Resize((32,32)),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                                                          std=[0.2023, 0.1994, 0.2010])\n",
        "                                     ])\n",
        "\n",
        "training_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    transform=data_transformer,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "validation_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    transform=data_transformer,\n",
        "    download=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model training parameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 0.001 # TOO LOW OR TOO HIGH of a lr leads to convergence issues (nan) during training\n",
        "\n",
        "training_data_loader = DataLoader(\n",
        "    dataset=training_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sampler=RandomSampler(training_set)\n",
        ")\n",
        "\n",
        "validation_data_loader = DataLoader(\n",
        "    dataset=validation_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sampler=SequentialSampler(validation_set)\n",
        ")"
      ],
      "metadata": {
        "id": "1_Y09usZcs6B"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = ImageClassifierModel()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    params=model.parameters(),\n",
        "    lr=LEARNING_RATE\n",
        ")\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "best_accuracy = 0.0\n",
        "for epoch in range(EPOCHS):\n",
        "  model.train()\n",
        "  training_progress_bar = tqdm(training_data_loader, desc=f\"Epoch {epoch + 1} - Training\")\n",
        "  for idx, (images, target_labels) in enumerate(training_progress_bar):\n",
        "    images = images.to(device)\n",
        "    target_labels = target_labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = loss_function(outputs, target_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    training_progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "\n",
        "  # testing how good our model is at classifying the sentences\n",
        "  model.eval()\n",
        "  total_correct = 0\n",
        "  total_samples = 0\n",
        "  validation_progress_bar = tqdm(validation_data_loader, desc=f\"Epoch {epoch + 1} - Testing\")\n",
        "  with torch.no_grad():\n",
        "    for idx, (images, target_labels) in enumerate(validation_progress_bar):\n",
        "      images = images.to(device)\n",
        "      target_labels = target_labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      _, predictions = torch.max(outputs.data, 1)\n",
        "      total_correct += (predictions == target_labels).sum().item()\n",
        "      total_samples += target_labels.size(0)\n",
        "    print(f\"epoch: {epoch+1}, accuracy: {100 * (total_correct / total_samples)}\")\n",
        "\n",
        "  current_accuracy = total_correct / total_samples\n",
        "  if current_accuracy > best_accuracy:\n",
        "    best_accuracy = current_accuracy\n",
        "    torch.save(model, \"./model/image_classifier_cnn.pth\")\n",
        "\n",
        "print(\"done training!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwtYdR6m0bVW",
        "outputId": "f7e56756-7308-4a5c-a1cd-1680594dca4a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - Training: 100%|██████████| 782/782 [00:19<00:00, 39.48it/s, loss=1.18]\n",
            "Epoch 1 - Testing: 100%|██████████| 157/157 [00:03<00:00, 51.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, accuracy: 61.42999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - Training: 100%|██████████| 782/782 [00:20<00:00, 38.48it/s, loss=0.773]\n",
            "Epoch 2 - Testing: 100%|██████████| 157/157 [00:02<00:00, 58.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2, accuracy: 67.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - Training: 100%|██████████| 782/782 [00:20<00:00, 37.81it/s, loss=0.621]\n",
            "Epoch 3 - Testing: 100%|██████████| 157/157 [00:02<00:00, 57.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 3, accuracy: 68.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - Training: 100%|██████████| 782/782 [00:20<00:00, 38.14it/s, loss=0.325]\n",
            "Epoch 4 - Testing: 100%|██████████| 157/157 [00:03<00:00, 52.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 4, accuracy: 70.28999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - Training: 100%|██████████| 782/782 [00:19<00:00, 39.55it/s, loss=0.443]\n",
            "Epoch 5 - Testing: 100%|██████████| 157/157 [00:03<00:00, 45.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 5, accuracy: 71.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 - Training: 100%|██████████| 782/782 [00:19<00:00, 39.56it/s, loss=0.443]\n",
            "Epoch 6 - Testing: 100%|██████████| 157/157 [00:02<00:00, 58.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 6, accuracy: 70.78999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 - Training: 100%|██████████| 782/782 [00:20<00:00, 37.79it/s, loss=0.738]\n",
            "Epoch 7 - Testing: 100%|██████████| 157/157 [00:02<00:00, 54.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 7, accuracy: 69.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 - Training: 100%|██████████| 782/782 [00:21<00:00, 36.86it/s, loss=0.359]\n",
            "Epoch 8 - Testing: 100%|██████████| 157/157 [00:03<00:00, 42.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 8, accuracy: 69.82000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 - Training: 100%|██████████| 782/782 [00:19<00:00, 39.74it/s, loss=0.51]\n",
            "Epoch 9 - Testing: 100%|██████████| 157/157 [00:03<00:00, 45.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 9, accuracy: 70.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 - Training: 100%|██████████| 782/782 [00:19<00:00, 39.30it/s, loss=0.614]\n",
            "Epoch 10 - Testing: 100%|██████████| 157/157 [00:02<00:00, 56.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, accuracy: 69.03\n",
            "done training!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_pretrained(\n",
        "#   save_directory=\"./model\",\n",
        "#   state_dict=model.state_dict(),\n",
        "#   push_to_hub=True,\n",
        "#   repo_id=\"ghislainehaha/image-classifier-cnn\",\n",
        "# )"
      ],
      "metadata": {
        "id": "DZT8r_2411hJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}